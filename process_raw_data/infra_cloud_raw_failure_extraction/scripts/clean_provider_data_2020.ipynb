{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-5c449a808df3>:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "project_dir = str(Path(os.getcwd()).parent)\n",
    "datasets_path = project_dir + \"/datasets/\"\n",
    "\n",
    "uncleaned_df = pd.read_parquet(datasets_path + 'dirty_2020_provider_data.parquet')\n",
    "uncleaned_df = uncleaned_df.drop(uncleaned_df.index[range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to timestamps\n",
    "uncleaned_df['event_start_time'] = pd.to_datetime(uncleaned_df['event_start_time'], unit='s')\n",
    "uncleaned_df['event_end_time'] = pd.to_datetime(uncleaned_df['event_end_time'], unit='s')\n",
    "uncleaned_df['first_notification'] = pd.to_datetime(uncleaned_df['first_notification'], unit='s')\n",
    "uncleaned_df['last_notification'] = pd.to_datetime(uncleaned_df['last_notification'], unit='s')\n",
    "\n",
    "# Drop duplicate rows\n",
    "uncleaned_df = uncleaned_df.drop_duplicates(inplace = False).reset_index(drop=True)\n",
    "\n",
    "# Drop duplicate event start and end times\n",
    "uncleaned_df = uncleaned_df.drop_duplicates(inplace = False, subset=['event_start_time', 'service_name']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Remove failures that didn't occur in 2020\n",
    "df_2020 = pd.DataFrame()\n",
    "for _, row in uncleaned_df.sort_values(\"event_start_time\").iterrows():\n",
    "    if row[\"event_start_time\"].year == 2020:\n",
    "        df_2020 = df_2020.append(row, ignore_index=True)[uncleaned_df.columns.tolist()].reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if event start time is later than end time\n",
    "broken_event_times_index = list()\n",
    "for idx, row in df_2020.sort_values(\"event_start_time\").iterrows():\n",
    "    if row[\"event_start_time\"] > row[\"event_end_time\"] or not row[\"event_start_time\"] or not row[\"event_end_time\"]:\n",
    "        broken_event_times_index.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25     6:08 PM PST \\nWe are currently experiencing an issue provisioning new image builder and fleet streaming instances in the AP-SOUTHEAST-2 Region. 7:20 PM PST \\nWe are continuing to investigate an increase in instance provisioning error rates in the AP-SOUTHEAST-2 Region. 8:32 PM PST \\nWe have identified the cause of the increased provisioning error rates in the AP-SOUTHEAST-2 Region and continue working towards resolution. 8:59 PM PST \\nWe continue to experience increased instance provisioning error rates due to the issue affecting EC2 within the AP-SOUTHEAST-2 Region. We continue to work towards full resolution. Existing streaming sessions and instances will continue to operate.Jan 23, 12:41 AM PST \\nWe continue to experience increased instance provisioning error rates within the AP-SOUTHEAST-2 Region. We continue to work towards full resolution. Existing streaming sessions and instances will continue to operate.Jan 23,  1:51 AM PST \\nWe are continuing to work towards resolution of increased instance provisioning error rates within the AP-SOUTHEAST-2 Region. Existing streaming sessions and instances will continue to operate.Jan 23,  2:38 AM PST \\nWe recently experienced increased instance provisioning errors within the AP-SOUTHEAST-2 Region. The issue has been resolved and the service is operating normally.\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_event_times_index\n",
    "df_2020[25:26].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehmetberk.cetin/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Fixing the event start times for service id 23: http://arpio.io/behind-the-aws-sydney-outage/\n",
    "df_2020[22:23].event_start_time = pd.Timestamp(year=2020, month=1, day=23, hour=16, minute=7) # PST\n",
    "df_2020[22:23].event_end_time = pd.Timestamp(year=2020, month=1, day=23, hour=23, minute=20) # PST\n",
    "df_2020[22:23].first_notification = pd.Timestamp(year=2020, month=1, day=23, hour=16, minute=41) # PST\n",
    "df_2020[22:23].last_notification = pd.Timestamp(year=2020, month=1, day=23, hour=23, minute=20) # PST\n",
    "\n",
    "df_2020[25:26].event_start_time = pd.Timestamp(year=2020, month=1, day=22, hour=18, minute=8) # PST\n",
    "df_2020[25:26].event_end_time = pd.Timestamp(year=2020, month=1, day=23, hour=2, minute=38) # PST\n",
    "df_2020[25:26].first_notification = pd.Timestamp(year=2020, month=1, day=22, hour=18, minute=8) # PST\n",
    "df_2020[25:26].last_notification = pd.Timestamp(year=2020, month=1, day=23, hour=2, minute=38) # PST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "df_2020.to_parquet(datasets_path + \"2020_fixed_sesaeet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to excel file for manual inspection\n",
    "df_2020.to_excel('dirty_2020_provider_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
